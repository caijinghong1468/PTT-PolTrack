{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a6a7545-1204-4e3f-a3c5-2d5d19369cb4",
   "metadata": {},
   "source": [
    "# **ğŸ¦¹ğŸ¼Modelè¨“ç·´**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008b3b82-a6d5-4643-96ef-291d2452a5f6",
   "metadata": {},
   "source": [
    "### ğŸ§° å®‰è£å·¥å…·ç®±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2b2c0ecf-031e-4327-abbf-0beb1a1f5a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è³‡æ–™å‰è™•ç†\n",
    "import os\n",
    "from os import path\n",
    "import jieba\n",
    "from sklearn.model_selection import train_test_split # ç”¨ä¾†åˆ‡å‰²è³‡æ–™é›†\n",
    "from sklearn.preprocessing import LabelEncoder # ç”¨ä¾†å°‡æ¨™ç±¤è½‰æ›æˆæ©Ÿå™¨çœ‹å¾—æ‡‚çš„æ ¼å¼\n",
    "from sklearn import tree # å¾sklearnçš„æ¨¡å‹é¸æ“‡å·¥å…·ç®±è£¡é¢æŠŠç”¨ä¾†è¨“ç·´æ¨¡å‹çš„å·¥å…·æ‹¿å‡ºä¾†\n",
    "import pandas as pd # ç”¨ä¾†é–‹å•Ÿè³‡æ–™é›†\n",
    "import re # ç”¨ä¾†æŠ“å–æˆ–è€…æ¸…ç†è³‡æ–™ä¸­çš„è³‡è¨Š\n",
    "# æŠ“å–ç‰¹å¾µ\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# è¨“ç·´æ¨¡å‹\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# è©•ä¼°æ¨¡å‹\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "def text_length(data):\n",
    "  sentence_length=[]\n",
    "  for comment in data:\n",
    "    length=len(comment)\n",
    "    sentence_length.append(length)\n",
    "  return sentence_length\n",
    "\n",
    "def frequency(data,regex):\n",
    "  freq=[]\n",
    "  for string in data:\n",
    "      count = len(re.findall(regex, string))\n",
    "      freq.append(count)\n",
    "  return freq\n",
    "\n",
    "def boolean(data, regex):\n",
    "  boolean_list = []\n",
    "  for comment in data:\n",
    "    word_match = bool(re.search(regex, comment))\n",
    "    boolean_list.append(word_match)\n",
    "  return boolean_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0d6b16-0a37-44b9-aede-bb422ed452fa",
   "metadata": {},
   "source": [
    "### ğŸªš é€™æ˜¯ç”¨ä¾†**æ–·è©**çš„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b8c1f29c-4a3f-4b9c-a730-9599034a89e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment(text):\n",
    "  return jieba.lcut(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d590f5df-ca06-4953-9c28-6599e7715c6a",
   "metadata": {},
   "source": [
    "### ğŸ” é€™æ˜¯ç”¨ä¾†**æŠ“å–ç‰¹å¾µ**çš„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2aabbc15-0503-4f06-9b4f-8d82ce8a4361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract(text, vectorizer):\n",
    "  # å°‡ list å…ƒç´ è½‰æ›ç‚ºå­—ä¸²\n",
    "  text = [' '.join(tokens) for tokens in text]  \n",
    "  matrix = vectorizer.fit_transform(text)\n",
    "  array = vectorizer.get_feature_names_out()\n",
    "  feature_df = pd.DataFrame(matrix.toarray(), columns = array)\n",
    "  return feature_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fb35cf-f51f-4297-9842-de1193475019",
   "metadata": {},
   "source": [
    "### âš™ï¸ é€™æ˜¯ç”¨ä¾†**è¨“ç·´æ¨¡å‹**çš„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e01d7564-7840-4733-8a8b-a235445ad10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "  def __init__(self, feature, label, model):\n",
    "    self.feature = feature\n",
    "    self.label = label\n",
    "    self.model = model\n",
    "\n",
    "  # å°‡ data åˆ†ç‚º training set & test set\n",
    "  def split_data(self):\n",
    "    self.feat_train, self.feat_test, self.label_train, self.label_test = train_test_split(self.feature, self.label, test_size=0.2, random_state = 123) # test_size=0.2è¡¨ç¤ºtest setä½”20%\n",
    "\n",
    "  # ç”¨training set è¨“ç·´æ¨¡å‹\n",
    "  def model_train(self):\n",
    "    self.model.fit(self.feat_train, self.label_train)\n",
    "\n",
    "  # ç”¨è¨“ç·´å¥½çš„æ¨¡å‹é æ¸¬ test set\n",
    "  def model_predict(self):\n",
    "    self.prediction = self.model.predict(self.feat_test)\n",
    "    print('predicted result: ' + str(self.prediction))\n",
    "\n",
    "  # è©•ä¼°æ¨¡å‹è¡¨ç¾\n",
    "  def model_evaluate(self):\n",
    "    print(ConfusionMatrixDisplay.from_predictions(self.label_test, self.prediction, cmap = \"Blues\")) # æ··æ·†çŸ©é™£\n",
    "    evaluation = precision_recall_fscore_support(self.label_test, self.prediction, average='macro') # è¨ˆç®— precision, recall, F-score\n",
    "    accuracy = accuracy_score(self.label_test, self.prediction) # è¨ˆç®— accuracy\n",
    "    print(\"accuracy: \" + str(round(accuracy, 2)) + \"\\nprecision: \" + str(round(evaluation[0], 2)) + \"\\nrecall: \" + str(round(evaluation[1], 2)) + \"\\nfscore: \" + str(round(evaluation[2],2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3fba9a-48c5-4837-a45f-b7a991dba858",
   "metadata": {},
   "source": [
    " ### ğŸ§»ä½¿ç”¨jiebaåšæ–·è©èˆ‡åˆªé™¤stopwords\n",
    "   ##### ç¨‹å¼å…§å®¹ï¼š\n",
    " - è¼‰å…¥åœç”¨è©å’Œä½¿ç”¨è€…å­—å…¸\n",
    " - ä½¿ç”¨jiebaæ–·è©ä¸¦ç§»é™¤æ–·è©ä¸­çš„åœç”¨è©ï¼Œæœ€å¾Œå°‡è™•ç†å¾Œçš„çµæœå­˜å›å…§æ–‡æ¬„ä½ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f171b0-3fca-4192-964f-13aa01438379",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "df_new = pd.DataFrame()\n",
    "file = './src/jieba_clean_result.csv'\n",
    "stopword = open(\"./src/stopwords_zhTW.txt\", \"r\", encoding='UTF-8').read()\n",
    "stopword_list = stopword.split(\"\\n\")\n",
    "df = pd.read_csv('./src/original_data.csv')\n",
    "new_word = open(\"./src/my_dict.txt\", \"r\", encoding='UTF-8').read()\n",
    "jieba.load_userdict(\"./src/my_dict.txt\")\n",
    "for text in df['å…§æ–‡']:\n",
    "  jieba_clean_result = []\n",
    "  jieba_result = jieba.lcut(text)\n",
    "  for token in jieba_result:\n",
    "    if token not in stopword_list:\n",
    "      jieba_clean_result.append(token)\n",
    "  output.append(jieba_clean_result)\n",
    "df_new['jieba_clean_result'] = output\n",
    "df_new.to_csv(file,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce49dcd6-4f67-40e3-b1ff-caaf7b553e43",
   "metadata": {},
   "source": [
    "### ğŸ“‘ TF-IDF\n",
    "ä¸€æ¨£ç”¨`feature_extract()`çš„åŠŸèƒ½\\\n",
    "`TfidfVectorizer()` æ˜¯è¨ˆç®— TF-IDF çš„å·¥å…·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0b4308-3686-4e4d-aa60-b5367b836653",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfidf_feature = feature_extract(df_new['jieba_clean_result'], TfidfVectorizer(tokenizer = segment))\n",
    "tfidf_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033f3d03-b6a9-4ca6-b394-a3ab3378099d",
   "metadata": {},
   "source": [
    "## âš™ï¸ è¨“ç·´æ¨¡å‹\n",
    "æˆ‘å€‘ä½¿ç”¨äº”ç¨®åˆ†é¡æ¨¡å‹ï¼š\n",
    "- æ±ºç­–æ¨¹ Decision Tree\n",
    "- éš¨æ©Ÿæ£®æ— Random Forest\n",
    "- ç¾…å‰æ–¯è¿´æ­¸ Logistic Regression\n",
    "- æ”¯æ´å‘é‡æ©Ÿ Support Vector Machine\n",
    "- å¤šé …å¼å‹æ¨¸ç´ è²è‘‰æ–¯ Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17861c78-0f13-46fc-9fb0-c9634c65e738",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier(criterion = 'entropy', max_depth = 5 , random_state = 123)\n",
    "RF = RandomForestClassifier(n_estimators = 120 , criterion = 'gini', max_depth = 10 , random_state = 123)\n",
    "LR = LogisticRegression(random_state = 1223)\n",
    "SVM = SVC(C=1, gamma='auto', kernel='linear', random_state = 123)\n",
    "NB = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf42075-083a-4951-805f-b60d6ec6de60",
   "metadata": {},
   "source": [
    "## âš™ï¸ Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6450a29-9318-4aca-8c85-bf4b0827a678",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_model_bow = Model(tfidf_feature,df['label'], DT)  \n",
    "DT_model_bow.split_data()  \n",
    "DT_model_bow.model_train()  \n",
    "DT_model_bow.model_predict()  \n",
    "DT_model_bow.model_evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206b1eb9-fa7c-4a99-8bb1-1d5ecc0922de",
   "metadata": {},
   "source": [
    "## âš™ï¸ Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408010ad-7882-4932-bb02-5b2d03c12863",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model_bow = Model(tfidf_feature,df['label'], RF)  \n",
    "RF_model_bow.split_data()  \n",
    "RF_model_bow.model_train()  \n",
    "RF_model_bow.model_predict()  \n",
    "RF_model_bow.model_evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed85e71-b9f9-43aa-bb81-c8105547d96b",
   "metadata": {},
   "source": [
    "## âš™ï¸ Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ac7dbf-2636-421e-9d9e-114a15a32625",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_model_bow = Model(tfidf_feature,df['label'], LR)  \n",
    "LR_model_bow.split_data()  \n",
    "LR_model_bow.model_train()  \n",
    "LR_model_bow.model_predict()  \n",
    "LR_model_bow.model_evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71df79b2-b079-4ce4-8c29-98254337295d",
   "metadata": {},
   "source": [
    "## âš™ï¸ Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f260eb-f440-4b0a-a799-a1c808a0bf62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SVM_model_bow = Model(tfidf_feature,df['label'], SVM)  \n",
    "SVM_model_bow.split_data()  \n",
    "SVM_model_bow.model_train()  \n",
    "SVM_model_bow.model_predict()  \n",
    "SVM_model_bow.model_evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cdcbd2-93af-4616-b36d-26b5981eadc3",
   "metadata": {},
   "source": [
    "## âš™ï¸ Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10be360e-4638-4b8b-89be-782e45893334",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_model_bow = Model(tfidf_feature,df['label'], NB)  \n",
    "NB_model_bow.split_data()  \n",
    "NB_model_bow.model_train()  \n",
    "NB_model_bow.model_predict()  \n",
    "NB_model_bow.model_evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
