{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a6a7545-1204-4e3f-a3c5-2d5d19369cb4",
   "metadata": {},
   "source": [
    "# **🦹🏼Model訓練**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008b3b82-a6d5-4643-96ef-291d2452a5f6",
   "metadata": {},
   "source": [
    "### 🧰 安裝工具箱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2b2c0ecf-031e-4327-abbf-0beb1a1f5a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料前處理\n",
    "import os\n",
    "from os import path\n",
    "import jieba\n",
    "from sklearn.model_selection import train_test_split # 用來切割資料集\n",
    "from sklearn.preprocessing import LabelEncoder # 用來將標籤轉換成機器看得懂的格式\n",
    "from sklearn import tree # 從sklearn的模型選擇工具箱裡面把用來訓練模型的工具拿出來\n",
    "import pandas as pd # 用來開啟資料集\n",
    "import re # 用來抓取或者清理資料中的資訊\n",
    "# 抓取特徵\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 訓練模型\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# 評估模型\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "def text_length(data):\n",
    "  sentence_length=[]\n",
    "  for comment in data:\n",
    "    length=len(comment)\n",
    "    sentence_length.append(length)\n",
    "  return sentence_length\n",
    "\n",
    "def frequency(data,regex):\n",
    "  freq=[]\n",
    "  for string in data:\n",
    "      count = len(re.findall(regex, string))\n",
    "      freq.append(count)\n",
    "  return freq\n",
    "\n",
    "def boolean(data, regex):\n",
    "  boolean_list = []\n",
    "  for comment in data:\n",
    "    word_match = bool(re.search(regex, comment))\n",
    "    boolean_list.append(word_match)\n",
    "  return boolean_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0d6b16-0a37-44b9-aede-bb422ed452fa",
   "metadata": {},
   "source": [
    "### 🪚 這是用來**斷詞**的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b8c1f29c-4a3f-4b9c-a730-9599034a89e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment(text):\n",
    "  return jieba.lcut(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d590f5df-ca06-4953-9c28-6599e7715c6a",
   "metadata": {},
   "source": [
    "### 🔍 這是用來**抓取特徵**的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2aabbc15-0503-4f06-9b4f-8d82ce8a4361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extract(text, vectorizer):\n",
    "  # 將 list 元素轉換為字串\n",
    "  text = [' '.join(tokens) for tokens in text]  \n",
    "  matrix = vectorizer.fit_transform(text)\n",
    "  array = vectorizer.get_feature_names_out()\n",
    "  feature_df = pd.DataFrame(matrix.toarray(), columns = array)\n",
    "  return feature_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fb35cf-f51f-4297-9842-de1193475019",
   "metadata": {},
   "source": [
    "### ⚙️ 這是用來**訓練模型**的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e01d7564-7840-4733-8a8b-a235445ad10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "  def __init__(self, feature, label, model):\n",
    "    self.feature = feature\n",
    "    self.label = label\n",
    "    self.model = model\n",
    "\n",
    "  # 將 data 分為 training set & test set\n",
    "  def split_data(self):\n",
    "    self.feat_train, self.feat_test, self.label_train, self.label_test = train_test_split(self.feature, self.label, test_size=0.2, random_state = 123) # test_size=0.2表示test set佔20%\n",
    "\n",
    "  # 用training set 訓練模型\n",
    "  def model_train(self):\n",
    "    self.model.fit(self.feat_train, self.label_train)\n",
    "\n",
    "  # 用訓練好的模型預測 test set\n",
    "  def model_predict(self):\n",
    "    self.prediction = self.model.predict(self.feat_test)\n",
    "    print('predicted result: ' + str(self.prediction))\n",
    "\n",
    "  # 評估模型表現\n",
    "  def model_evaluate(self):\n",
    "    print(ConfusionMatrixDisplay.from_predictions(self.label_test, self.prediction, cmap = \"Blues\")) # 混淆矩陣\n",
    "    evaluation = precision_recall_fscore_support(self.label_test, self.prediction, average='macro') # 計算 precision, recall, F-score\n",
    "    accuracy = accuracy_score(self.label_test, self.prediction) # 計算 accuracy\n",
    "    print(\"accuracy: \" + str(round(accuracy, 2)) + \"\\nprecision: \" + str(round(evaluation[0], 2)) + \"\\nrecall: \" + str(round(evaluation[1], 2)) + \"\\nfscore: \" + str(round(evaluation[2],2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3fba9a-48c5-4837-a45f-b7a991dba858",
   "metadata": {},
   "source": [
    " ### 🧻使用jieba做斷詞與刪除stopwords\n",
    "   ##### 程式內容：\n",
    " - 載入停用詞和使用者字典\n",
    " - 使用jieba斷詞並移除斷詞中的停用詞，最後將處理後的結果存回內文欄位。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f171b0-3fca-4192-964f-13aa01438379",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "df_new = pd.DataFrame()\n",
    "file = './src/jieba_clean_result.csv'\n",
    "stopword = open(\"./src/stopwords_zhTW.txt\", \"r\", encoding='UTF-8').read()\n",
    "stopword_list = stopword.split(\"\\n\")\n",
    "df = pd.read_csv('./src/original_data.csv')\n",
    "new_word = open(\"./src/my_dict.txt\", \"r\", encoding='UTF-8').read()\n",
    "jieba.load_userdict(\"./src/my_dict.txt\")\n",
    "for text in df['內文']:\n",
    "  jieba_clean_result = []\n",
    "  jieba_result = jieba.lcut(text)\n",
    "  for token in jieba_result:\n",
    "    if token not in stopword_list:\n",
    "      jieba_clean_result.append(token)\n",
    "  output.append(jieba_clean_result)\n",
    "df_new['jieba_clean_result'] = output\n",
    "df_new.to_csv(file,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce49dcd6-4f67-40e3-b1ff-caaf7b553e43",
   "metadata": {},
   "source": [
    "### 📑 TF-IDF\n",
    "一樣用`feature_extract()`的功能\\\n",
    "`TfidfVectorizer()` 是計算 TF-IDF 的工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0b4308-3686-4e4d-aa60-b5367b836653",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfidf_feature = feature_extract(df_new['jieba_clean_result'], TfidfVectorizer(tokenizer = segment))\n",
    "tfidf_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033f3d03-b6a9-4ca6-b394-a3ab3378099d",
   "metadata": {},
   "source": [
    "## ⚙️ 訓練模型\n",
    "我們使用五種分類模型：\n",
    "- 決策樹 Decision Tree\n",
    "- 隨機森林 Random Forest\n",
    "- 羅吉斯迴歸 Logistic Regression\n",
    "- 支援向量機 Support Vector Machine\n",
    "- 多項式型樸素貝葉斯 Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17861c78-0f13-46fc-9fb0-c9634c65e738",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier(criterion = 'entropy', max_depth = 5 , random_state = 123)\n",
    "RF = RandomForestClassifier(n_estimators = 120 , criterion = 'gini', max_depth = 10 , random_state = 123)\n",
    "LR = LogisticRegression(random_state = 1223)\n",
    "SVM = SVC(C=1, gamma='auto', kernel='linear', random_state = 123)\n",
    "NB = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf42075-083a-4951-805f-b60d6ec6de60",
   "metadata": {},
   "source": [
    "## ⚙️ Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6450a29-9318-4aca-8c85-bf4b0827a678",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_model_bow = Model(tfidf_feature,df['label'], DT)  \n",
    "DT_model_bow.split_data()  \n",
    "DT_model_bow.model_train()  \n",
    "DT_model_bow.model_predict()  \n",
    "DT_model_bow.model_evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206b1eb9-fa7c-4a99-8bb1-1d5ecc0922de",
   "metadata": {},
   "source": [
    "## ⚙️ Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408010ad-7882-4932-bb02-5b2d03c12863",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_model_bow = Model(tfidf_feature,df['label'], RF)  \n",
    "RF_model_bow.split_data()  \n",
    "RF_model_bow.model_train()  \n",
    "RF_model_bow.model_predict()  \n",
    "RF_model_bow.model_evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed85e71-b9f9-43aa-bb81-c8105547d96b",
   "metadata": {},
   "source": [
    "## ⚙️ Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ac7dbf-2636-421e-9d9e-114a15a32625",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_model_bow = Model(tfidf_feature,df['label'], LR)  \n",
    "LR_model_bow.split_data()  \n",
    "LR_model_bow.model_train()  \n",
    "LR_model_bow.model_predict()  \n",
    "LR_model_bow.model_evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71df79b2-b079-4ce4-8c29-98254337295d",
   "metadata": {},
   "source": [
    "## ⚙️ Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f260eb-f440-4b0a-a799-a1c808a0bf62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SVM_model_bow = Model(tfidf_feature,df['label'], SVM)  \n",
    "SVM_model_bow.split_data()  \n",
    "SVM_model_bow.model_train()  \n",
    "SVM_model_bow.model_predict()  \n",
    "SVM_model_bow.model_evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cdcbd2-93af-4616-b36d-26b5981eadc3",
   "metadata": {},
   "source": [
    "## ⚙️ Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10be360e-4638-4b8b-89be-782e45893334",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_model_bow = Model(tfidf_feature,df['label'], NB)  \n",
    "NB_model_bow.split_data()  \n",
    "NB_model_bow.model_train()  \n",
    "NB_model_bow.model_predict()  \n",
    "NB_model_bow.model_evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
