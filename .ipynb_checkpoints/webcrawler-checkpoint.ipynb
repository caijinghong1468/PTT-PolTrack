{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d25fb325-0493-462e-a70c-5de4b2c4096d",
   "metadata": {},
   "source": [
    "### 📦載入套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10363824-4c7b-4b4c-9fc8-175d1814c775",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f17cd44-beb1-448a-a6b9-87a20fc2ff31",
   "metadata": {},
   "source": [
    "### 📃抓取 PTT「HatePolitics」板單個文章資訊的函式\n",
    "#####  步驟分別是：\n",
    "- 需要點擊文章網址後，才能抓取文章內容\n",
    "- 點擊網址後，簡單驗證文章以及抓取文章內文\n",
    "- 最後以清單形式返回所有文章的資訊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1853bad9-e50c-4775-8cd8-405d1d87ef5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   建立函式\n",
    "def get_ptt_post(soup):\n",
    "\n",
    "    #   CH2 - 取得文章列表\n",
    "    #   目標 div\n",
    "    data = soup.select(\"div.r-ent\")\n",
    "    result = []\n",
    "    for i in data:\n",
    "\n",
    "        #   4 - 網址\n",
    "        #   PTT 網站\n",
    "        oriLink = \"https://www.ptt.cc\" + i.select(\"div.title a\")[0][\"href\"]\n",
    "\n",
    "        #   CH3 - 取得文章相關資訊\n",
    "        #   8 - 內文\n",
    "        #   8.1 - 請求文章內文\n",
    "        res_content = requests.get(oriLink)\n",
    "        soup_content = bs(res_content.text,\"lxml\")\n",
    "        #   8.2 - 文章內容簡易驗證\n",
    "        results_content = soup_content.select('span.article-meta-value')\n",
    "        if len(results_content) > 3:\n",
    "            #   8.2.1 - 驗證成功, 篩出文章內文\n",
    "            content = soup_content.find(id=\"main-content\").text\n",
    "            Footer = u'※ 發信站: 批踢踢實業坊(ptt.cc),'\n",
    "            #   8.3 - 移除註腳以下內容\n",
    "            content = content.split(Footer)\n",
    "            #   8.4 - 存取內容\n",
    "            main_content = content[0]\n",
    "            pass\n",
    "        else:\n",
    "            #   8.2.2 - 驗證失敗, 跳過該文章\n",
    "            print(oriLink,\"內文異常:ID/版標/標題/日期為空\")\n",
    "            print(results_content)\n",
    "            continue\n",
    "\n",
    "        result.append({\n",
    "            \"內文\":main_content\n",
    "        })\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df17f5df-dad7-4027-93a7-3eda0ff0fc0d",
   "metadata": {},
   "source": [
    "### 📃抓取 PTT「HatePolitics」板的多頁文章資訊\n",
    "#####  工作流程：\n",
    "- 前處理、解析網址\n",
    "- 抓取首頁文章\n",
    "- 自動抓取首頁前 N 頁的文章（N為手動輸入的頁數）\n",
    "- 將多頁文章整合成一個表格（DataFrame）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e0a96c2-4377-4682-8889-82711ed42e2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.ptt.cc/bbs/HatePolitics/index4166.html is ok\n",
      "https://www.ptt.cc/bbs/HatePolitics/index4165.html is ok\n",
      "https://www.ptt.cc/bbs/HatePolitics/index4164.html is ok\n",
      "https://www.ptt.cc/bbs/HatePolitics/index4163.html is ok\n",
      "https://www.ptt.cc/bbs/HatePolitics/index4162.html is ok\n"
     ]
    }
   ],
   "source": [
    "#   前綴與首頁網址\n",
    "prefix = \"https://www.ptt.cc\"\n",
    "url = \"https://www.ptt.cc/bbs/HatePolitics/index.html\"\n",
    "\n",
    "#   請求與解析\n",
    "res = requests.get(url)\n",
    "soup = bs(res.text,\"lxml\")\n",
    "\n",
    "\n",
    "#   建立資料集並匯出\n",
    "#   首次呼叫 Def\n",
    "output = []\n",
    "result = get_ptt_post(soup)\n",
    "\n",
    "#   將結果函式返回的內容存入output陣列\n",
    "output += result\n",
    "\n",
    "#   再次呼叫數(N)頁 - 前頁網址\n",
    "N = 5\n",
    "previous_page = soup.select(\"div#action-bar-container div.action-bar div.btn-group-paging a\")[1][\"href\"]\n",
    "# Extract the page number using split and indexing\n",
    "page_number = int(previous_page.split('/')[-1].split('.')[0].replace('index',''))\n",
    "\n",
    "for i in range(N):\n",
    "    url = \"https://www.ptt.cc/bbs/HatePolitics/index{}\".format(page_number-i)+\".html\"\n",
    "    res = requests.get(url)\n",
    "    soup = bs(res.text,\"lxml\")\n",
    "\n",
    "    result = get_ptt_post(soup)\n",
    "    output += result\n",
    "    print(\"{} is ok\".format(url))\n",
    "\n",
    "#   產出資料集\n",
    "df = pd.DataFrame(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f4f4e3-be1c-4302-abfe-69e11eb18c1f",
   "metadata": {},
   "source": [
    " ### 🧻清理並格式化文章內文\n",
    " #####  使用正則表達處理內文的內容：\n",
    " - 先確認內文欄位存在\n",
    " - 一共使用三種方式整理內文：\n",
    "   1. 不屬於內文的文字都刪除\n",
    "   2. 內文只保留中文字以及數字\n",
    "   3. 把文章是新聞的都刪除\n",
    " - 將結果存在\"clean_processed_ptt_tech_job_post.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b32d835-b6ea-4f9e-a2d7-4b63a7996bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if '內文' in df.columns:\n",
    "    def process_text(text):\n",
    "        # 檢查是否為string\n",
    "        if isinstance(text, str):\n",
    "            #用正則表達處理內文\n",
    "            pattern = r'標題(.*?)時間.*?\\n(.*)'\n",
    "            match = re.search(pattern, text, re.DOTALL)\n",
    "            if match:\n",
    "                title = match.group(1).strip()\n",
    "                content = match.group(2).strip()\n",
    "                return f'{title}\\n{content}'\n",
    "        return text  # 如果不匹配，返回原文本或者非字符串類型\n",
    "\n",
    "    # 用re處理每行\n",
    "    df['內文'] = df['內文'].apply(process_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "254a87c0-554a-410d-8e72-1fb406d97f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = []\n",
    "for text in df['內文']:\n",
    "  # Check if the value is a string before applying re.sub\n",
    "  if isinstance(text, str):\n",
    "    clean = re.sub(r'(\\n|\\t|\\r|[a-z]|[A-Z]|http\\S+)', r'', text)\n",
    "    clean_text.append(clean)\n",
    "  else:\n",
    "    # Handle non-string values (e.g., NaN)\n",
    "    clean_text.append('')  # Or any other appropriate value\n",
    "\n",
    "# 清理完的text存成新的一欄 data\n",
    "df['內文'] = clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "610a36f3-e008-4590-b734-d4c723e16694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已移除含有 '[新聞]' 的列，結果儲存至 clean_processed_ptt_tech_job_post.csv\n"
     ]
    }
   ],
   "source": [
    "output_file = 'clean_processed_ptt_tech_job_post.csv'\n",
    "# 檢查 'clean_text' 欄位是否存在\n",
    "if '內文' in df.columns:\n",
    "    # 篩選資料，移除含有 \"[新聞]\" 的列\n",
    "    filtered_df = df[~df['內文'].str.contains(r'\\[新聞\\]', na=False)]\n",
    "    # 儲存到新的CSV檔案\n",
    "    filtered_df.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f\"已移除含有 '[新聞]' 的列，結果儲存至 {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
